{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPn/peoFDiGxfqcyoAvL9Bq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqzFq1e9HtGM","executionInfo":{"status":"ok","timestamp":1714203173448,"user_tz":-330,"elapsed":28077,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"80220d48-d257-4a79-c39f-0b0dbffc9c2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Path to your dataset folder\n","dataset_folder = '/content/drive/My Drive/masked_direct'"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, Dropout, Dense, Flatten, concatenate\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import InceptionV3\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import make_scorer, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from tensorflow.keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def build_cnn_model(input_shape):\n","    input_layer = Input(shape=input_shape)\n","    x = Conv2D(256, (3, 3), activation='relu')(input_layer)\n","    x = Activation('relu')(x)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","    x = BatchNormalization(axis=1)(x)\n","\n","    x = Conv2D(64, (3, 3), activation='relu')(x)\n","    x = Conv2D(16, (3, 3), activation='relu')(x)\n","\n","    x = Flatten()(x)\n","    x = Dense(1024, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(len(classes), activation='softmax')(x)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def ensemble_model(input_shape, num_classes):\n","    input_layer = Input(shape=input_shape)\n","\n","    # Inception-V3 base model\n","    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","    inception_output = base_model(input_layer)\n","    inception_output = Flatten()(inception_output)\n","\n","    # CNN model with 3x3 kernel\n","    cnn_model_3x3 = build_cnn_model(input_shape)\n","    cnn_output_3x3 = cnn_model_3x3(input_layer)\n","\n","    # CNN model with 5x5 kernel\n","    cnn_model_5x5 = build_cnn_model(input_shape)\n","    cnn_output_5x5 = cnn_model_5x5(input_layer)\n","\n","    # CNN model with 7x7 kernel\n","    cnn_model_7x7 = build_cnn_model(input_shape)\n","    cnn_output_7x7 = cnn_model_7x7(input_layer)\n","\n","    # Concatenate outputs\n","    concatenated = concatenate([inception_output, cnn_output_3x3, cnn_output_5x5, cnn_output_7x7], axis=-1)\n","\n","    # Fully connected layers\n","    x = Dense(1024, activation='relu')(concatenated)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def print_evaluation_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    roc_auc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","    print(\"Accuracy: {:.4f}\".format(accuracy))\n","    print(\"Precision: {:.4f}\".format(precision))\n","    print(\"Recall: {:.4f}\".format(recall))\n","    print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n","    print(\"F1 Score: {:.4f}\".format(f1))\n","\n","def plot_confusion_matrix(y_true, y_pred, classes):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n","    plt.xlabel('Predicted labels')\n","    plt.ylabel('True labels')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Check if GPU is available\n","gpu_info = !nvidia-smi\n","gpu_available = len(gpu_info) > 2\n","\n","if gpu_available:\n","    # Set GPU memory growth\n","    gpus = tf.config.experimental.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","        except RuntimeError as e:\n","            print(e)\n","    print(\"GPU is available\")\n","    device = tf.device(\"gpu:0\")\n","else:\n","    print(\"GPU is not available\")\n","    device = tf.device(\"cpu\")\n","\n","# Define dataset folder and classes\n","dataset_folder = '/content/drive/My Drive/masked_direct'\n","classes = sorted(os.listdir(dataset_folder))\n","\n","# Define input shape\n","input_shape = (512, 512, 3)\n","\n","# Define ensemble model\n","with device:\n","    model = ensemble_model(input_shape, len(classes))\n","\n","# Compile model\n","with device:\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display model summary\n","print(model.summary())\n","\n","# Data augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Define batch size\n","batch_size = 8\n","\n","# Load and prepare training data\n","train_generator = train_datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","# Load and prepare testing data\n","test_generator = test_datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False)\n","\n","# Train the model with early stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","with device:\n","    history = model.fit(\n","        train_generator,\n","        steps_per_epoch=train_generator.samples // batch_size,\n","        epochs=25,\n","        validation_data=test_generator,\n","        validation_steps=test_generator.samples // batch_size,\n","        callbacks=[early_stopping])\n","\n","# Evaluate the model\n","with device:\n","    y_true = test_generator.classes\n","    y_pred = np.argmax(model.predict(test_generator), axis=-1)\n","    print_evaluation_metrics(y_true, y_pred)\n","    plot_confusion_matrix(y_true, y_pred, classes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"9aI0RJGeHy4o","executionInfo":{"status":"error","timestamp":1714200661573,"user_tz":-330,"elapsed":20101,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"a271d409-606f-4bcc-c132-16bf5fa9555e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is not available\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/masked_direct'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4c2a9097561d>\u001b[0m in \u001b[0;36m<cell line: 111>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Define dataset folder and classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mdataset_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/masked_direct'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# Define input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/masked_direct'"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, concatenate, Dropout, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def build_cnn_model(input_shape):\n","    input_layer = Input(shape=input_shape)\n","    x = Conv2D(128, (3, 3), activation='relu')(input_layer)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def ensemble_model(input_shape, num_classes):\n","    input_layer = Input(shape=input_shape)\n","\n","    # Inception-V3 base model\n","    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","    inception_output = base_model(input_layer)\n","    inception_output = Flatten()(inception_output)\n","\n","    # CNN model\n","    cnn_model = build_cnn_model(input_shape)\n","    cnn_output = cnn_model(input_layer)\n","\n","    # Concatenate outputs\n","    concatenated = concatenate([inception_output, cnn_output], axis=-1)\n","\n","    # Fully connected layers\n","    x = Dense(1024, activation='relu')(concatenated)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def print_evaluation_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    roc_auc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","    print(\"Accuracy: {:.4f}\".format(accuracy))\n","    print(\"Precision: {:.4f}\".format(precision))\n","    print(\"Recall: {:.4f}\".format(recall))\n","    print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n","    print(\"F1 Score: {:.4f}\".format(f1))\n","\n","def plot_confusion_matrix(y_true, y_pred, classes):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n","    plt.xlabel('Predicted labels')\n","    plt.ylabel('True labels')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Enable TPU\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    print('Running on TPU:', tpu.master())\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","except ValueError:\n","    print('Running on GPU')\n","    tpu = None\n","    strategy = None\n","\n","# Define dataset folder and classes\n","dataset_folder = '/content/drive/My Drive/masked_direct'\n","classes = sorted(os.listdir(dataset_folder))\n","\n","# Define input shape\n","input_shape = (512, 512, 1)\n","num_classes = len(classes)\n","\n","# Define ensemble model\n","if strategy:\n","    with strategy.scope():\n","        model = ensemble_model(input_shape, num_classes)\n","else:\n","    model = ensemble_model(input_shape, num_classes)\n","\n","# Compile model\n","if strategy:\n","    with strategy.scope():\n","        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","else:\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display model summary\n","print(model.summary())\n","\n","# Data augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Define batch size\n","batch_size = 8\n","\n","# Load and prepare training data\n","train_generator = train_datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","# Load and prepare testing data\n","test_generator = test_datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    shuffle=False)\n","\n","# Train the model with early stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","with strategy.scope():\n","    history = model.fit(\n","        train_generator,\n","        steps_per_epoch=train_generator.samples // batch_size,\n","        epochs=25,\n","        validation_data=test_generator,\n","        validation_steps=test_generator.samples // batch_size,\n","        callbacks=[early_stopping])\n","\n","# Evaluate the model\n","with strategy.scope():\n","    y_true = test_generator.classes\n","    y_pred = np.argmax(model.predict(test_generator), axis=-1)\n","    print_evaluation_metrics(y_true, y_pred)\n","    plot_confusion_matrix(y_true, y_pred, classes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"cbthzDJLQSRi","executionInfo":{"status":"error","timestamp":1714201910876,"user_tz":-330,"elapsed":363,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"21850ed9-0f28-4e94-f0cf-df240d53634a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU: \n"]},{"output_type":"error","ename":"ValueError","evalue":"The input must have 3 channels; Received `input_shape=(512, 512, 1)`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9269479be864>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-9269479be864>\u001b[0m in \u001b[0;36mensemble_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Inception-V3 base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/inception_v3.py\u001b[0m in \u001b[0;36mInceptionV3\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# Determine proper input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    400\u001b[0m                     )\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    403\u001b[0m                         \u001b[0;34m\"The input must have 3 channels; Received \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                         \u001b[0;34mf\"`input_shape={input_shape}`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; Received `input_shape=(512, 512, 1)`"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"-1mWGeOJ5EiZ"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Path to your dataset folder\n","dataset_folder = '/content/drive/My Drive/masked_direct'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vK9V9Lffey_H","executionInfo":{"status":"ok","timestamp":1714210255572,"user_tz":-330,"elapsed":27123,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"7e167bcb-6f62-4e6f-95bf-9e6b47f355c1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, concatenate, Dropout, Dense, Lambda\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc  # For memory management\n","\n","def build_cnn_model(input_shape):\n","    input_layer = Input(shape=input_shape)\n","    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def ensemble_model(input_shape, num_classes):\n","    input_layer = Input(shape=input_shape)\n","\n","    # Preprocess grayscale to RGB\n","    rgb_layer = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(input_layer)\n","\n","    # Inception-V3 base model\n","    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n","    for layer in base_model.layers[:-50]:  # Freeze all but the last 50 layers\n","        layer.trainable = False\n","    inception_output = base_model(rgb_layer)\n","    inception_output = Flatten()(inception_output)\n","\n","    # CNN model\n","    cnn_model = build_cnn_model(input_shape)\n","    cnn_output = cnn_model(input_layer)\n","\n","    # Concatenate outputs\n","    concatenated = concatenate([inception_output, cnn_output], axis=-1)\n","\n","    # Fully connected layers\n","    x = Dense(256, activation='relu')(concatenated)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def print_evaluation_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    roc_auc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","    print(\"Accuracy: {:.4f}\".format(accuracy))\n","    print(\"Precision: {:.4f}\".format(precision))\n","    print(\"Recall: {:.4f}\".format(recall))\n","    print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n","    print(\"F1 Score: {:.4f}\".format(f1))\n","\n","def plot_confusion_matrix(y_true, y_pred, classes):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n","    plt.xlabel('Predicted labels')\n","    plt.ylabel('True labels')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Memory clearing\n","def clear_memory():\n","    gc.collect()\n","    tf.keras.backend.clear_session()\n","\n","# Data loading\n","def load_data(dataset_folder, target_size=(512, 512), batch_size=64, grayscale=True):\n","    train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","\n","    test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    train_generator = train_datagen.flow_from_directory(\n","        dataset_folder,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        color_mode='grayscale' if grayscale else 'rgb',\n","        class_mode='categorical')\n","\n","    test_generator = test_datagen.flow_from_directory(\n","        dataset_folder,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        color_mode='grayscale' if grayscale else 'rgb',\n","        class_mode='categorical',\n","        shuffle=False)\n","\n","    return train_generator, test_generator\n","\n","# Enable GPU\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device:', tf.test.gpu_device_name())\n","else:\n","    print(\"Please install GPU version of TF\")\n","\n","# Define dataset folder and classes\n","dataset_folder = '/content/drive/My Drive/masked_direct'\n","classes = sorted(os.listdir(dataset_folder))\n","\n","# Define input shape\n","input_shape = (512, 512, 1)  # Update to 1 channel for grayscale\n","num_classes = len(classes)\n","\n","# Define batch size\n","batch_size = 8\n","\n","# Load data\n","train_generator, test_generator = load_data(dataset_folder, target_size=(512, 512), batch_size=batch_size, grayscale=True)\n","\n","# Define ensemble model\n","model = ensemble_model(input_shape, num_classes)\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display model summary\n","print(model.summary())\n","\n","# Train the model with early stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=25,\n","    validation_data=test_generator,\n","    validation_steps=test_generator.samples // batch_size,\n","    callbacks=[early_stopping])\n","\n","# Evaluate the model\n","y_true = test_generator.classes\n","y_pred = np.argmax(model.predict(test_generator), axis=-1)\n","print_evaluation_metrics(y_true, y_pred)\n","plot_confusion_matrix(y_true, y_pred, classes)\n","\n","# Clear memory\n","clear_memory()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qzYq1m3sVGf-","executionInfo":{"status":"error","timestamp":1714205926244,"user_tz":-330,"elapsed":1920786,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"4d784845-a1c7-42ba-cbc6-90866d2449a6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Default GPU Device: /device:GPU:0\n","Found 3256 images belonging to 4 classes.\n","Found 3256 images belonging to 4 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 5s 0us/step\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n","                                                                                                  \n"," lambda (Lambda)             (None, 512, 512, 3)          0         ['input_1[0][0]']             \n","                                                                                                  \n"," inception_v3 (Functional)   (None, 14, 14, 2048)         2180278   ['lambda[0][0]']              \n","                                                          4                                       \n","                                                                                                  \n"," flatten (Flatten)           (None, 401408)               0         ['inception_v3[0][0]']        \n","                                                                                                  \n"," model (Functional)          (None, 4)                    2663433   ['input_1[0][0]']             \n","                                                          64                                      \n","                                                                                                  \n"," concatenate_2 (Concatenate  (None, 401412)               0         ['flatten[0][0]',             \n"," )                                                                   'model[0][0]']               \n","                                                                                                  \n"," dense_2 (Dense)             (None, 256)                  1027617   ['concatenate_2[0][0]']       \n","                                                          28                                      \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 256)                  0         ['dense_2[0][0]']             \n","                                                                                                  \n"," dense_3 (Dense)             (None, 4)                    1028      ['dropout_1[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 390908904 (1.46 GB)\n","Trainable params: 376279432 (1.40 GB)\n","Non-trainable params: 14629472 (55.81 MB)\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/25\n","407/407 [==============================] - 1395s 3s/step - loss: 3.5718 - accuracy: 0.5900 - val_loss: 0.5733 - val_accuracy: 0.7789\n","Epoch 2/25\n","407/407 [==============================] - 81s 198ms/step - loss: 0.8063 - accuracy: 0.6714 - val_loss: 0.5713 - val_accuracy: 0.7635\n","Epoch 3/25\n","407/407 [==============================] - 80s 197ms/step - loss: 0.7467 - accuracy: 0.6858 - val_loss: 0.5239 - val_accuracy: 0.7865\n","Epoch 4/25\n","407/407 [==============================] - 80s 196ms/step - loss: 0.7844 - accuracy: 0.7049 - val_loss: 0.4613 - val_accuracy: 0.7982\n","Epoch 5/25\n","407/407 [==============================] - 79s 195ms/step - loss: 0.6838 - accuracy: 0.7156 - val_loss: 0.6785 - val_accuracy: 0.7374\n","Epoch 6/25\n","407/407 [==============================] - 80s 197ms/step - loss: 0.6402 - accuracy: 0.7396 - val_loss: 0.4645 - val_accuracy: 0.8010\n","Epoch 7/25\n","407/407 [==============================] - 81s 199ms/step - loss: 0.6780 - accuracy: 0.7245 - val_loss: 0.5271 - val_accuracy: 0.7589\n","407/407 [==============================] - 16s 36ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"error","ename":"AxisError","evalue":"axis 1 is out of bounds for array of dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9c6f2673174a>\u001b[0m in \u001b[0;36m<cell line: 150>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mprint_evaluation_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-9c6f2673174a>\u001b[0m in \u001b[0;36mprint_evaluation_metrics\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         return _multiclass_roc_auc_score(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \"\"\"\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# validation of the input y_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         raise ValueError(\n\u001b[1;32m    640\u001b[0m             \u001b[0;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n","\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, concatenate, Dropout, Dense, Lambda\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc  # For memory management\n","\n","def build_cnn_model(input_shape, num_classes):\n","    input_layer = Input(shape=input_shape)\n","    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n","    x = MaxPooling2D(pool_size=(2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def vgg16_base_model(input_shape):\n","    vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","    for layer in vgg16_base.layers[:-5]:  # Freeze all but the last 5 layers\n","        layer.trainable = False\n","    output = Flatten()(vgg16_base.output)\n","    model = Model(inputs=vgg16_base.input, outputs=output)\n","    return model\n","\n","def ensemble_model(input_shape, num_classes):\n","    input_layer = Input(shape=input_shape)\n","\n","    # Preprocess grayscale to RGB\n","    rgb_layer = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(input_layer)\n","\n","    # VGG16 base model\n","    vgg16_model = vgg16_base_model((512, 512, 3))\n","    vgg16_output = vgg16_model(rgb_layer)\n","\n","    # CNN model\n","    cnn_model = build_cnn_model(input_shape, num_classes)\n","    cnn_output = cnn_model(input_layer)\n","\n","    # Concatenate outputs\n","    concatenated = concatenate([vgg16_output, cnn_output], axis=-1)\n","\n","    # Fully connected layers\n","    x = Dense(256, activation='relu')(concatenated)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(num_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","    return model\n","\n","def print_evaluation_metrics(y_true, y_pred, classes):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","    roc_auc = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","\n","    print(\"Accuracy: {:.4f}\".format(accuracy))\n","    print(\"Precision: {:.4f}\".format(precision))\n","    print(\"Recall: {:.4f}\".format(recall))\n","    print(\"ROC-AUC: {:.4f}\".format(roc_auc))\n","    print(\"F1 Score: {:.4f}\".format(f1))\n","\n","def plot_confusion_matrix(y_true, y_pred, classes):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n","    plt.xlabel('Predicted labels')\n","    plt.ylabel('True labels')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Memory clearing\n","def clear_memory():\n","    gc.collect()\n","    tf.keras.backend.clear_session()\n","\n","# Data loading\n","def load_data(dataset_folder, target_size=(512, 512), batch_size=64, grayscale=True):\n","    train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","\n","    test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    train_generator = train_datagen.flow_from_directory(\n","        dataset_folder,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        color_mode='grayscale' if grayscale else 'rgb',\n","        class_mode='categorical')\n","\n","    test_generator = test_datagen.flow_from_directory(\n","        dataset_folder,\n","        target_size=target_size,\n","        batch_size=batch_size,\n","        color_mode='grayscale' if grayscale else 'rgb',\n","        class_mode='categorical',\n","        shuffle=False)\n","\n","    return train_generator, test_generator\n","\n","# Standardize scale\n","def standardize_scale(image):\n","    return (image - np.mean(image)) / np.std(image)\n","\n","# Enable GPU\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device:', tf.test.gpu_device_name())\n","else:\n","    print(\"Please install GPU version of TF\")\n","\n","# Define dataset folder and classes\n","dataset_folder = '/content/drive/My Drive/masked_direct'\n","classes = sorted(os.listdir(dataset_folder))\n","\n","# Define input shape\n","input_shape = (512, 512, 1)  # Update to 1 channel for grayscale\n","num_classes = len(classes)\n","\n","# Define batch size\n","batch_size = 8\n","\n","# Load data\n","train_generator, test_generator = load_data(dataset_folder, target_size=(512, 512), batch_size=batch_size, grayscale=True)\n","\n","# Define ensemble model\n","model = ensemble_model(input_shape, num_classes)\n","\n","# Compile model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Display model summary\n","print(model.summary())\n","\n","# Train the model with early stopping\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=25,\n","    validation_data=test_generator,\n","    validation_steps=test_generator.samples // batch_size,\n","    callbacks=[early_stopping])\n","\n","# Evaluate the model\n","y_true = test_generator.classes\n","y_pred = np.argmax(model.predict(test_generator), axis=-1)\n","print_evaluation_metrics(y_true, y_pred, classes)\n","plot_confusion_matrix(y_true, y_pred, classes)\n","\n","# Clear memory\n","clear_memory()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oKdoXTuIx2ae","executionInfo":{"status":"error","timestamp":1714210166740,"user_tz":-330,"elapsed":1565095,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"e517c1ad-7431-426d-8720-5250b9345b4e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Default GPU Device: /device:GPU:0\n","Found 4402 images belonging to 4 classes.\n","Found 4402 images belonging to 4 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n","                                                                                                  \n"," lambda (Lambda)             (None, 512, 512, 3)          0         ['input_1[0][0]']             \n","                                                                                                  \n"," model (Functional)          (None, 131072)               1471468   ['lambda[0][0]']              \n","                                                          8                                       \n","                                                                                                  \n"," model_1 (Functional)        (None, 4)                    2663433   ['input_1[0][0]']             \n","                                                          64                                      \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 131076)               0         ['model[0][0]',               \n","                                                                     'model_1[0][0]']             \n","                                                                                                  \n"," dense_3 (Dense)             (None, 256)                  3355571   ['concatenate[0][0]']         \n","                                                          2                                       \n","                                                                                                  \n"," dropout_2 (Dropout)         (None, 256)                  0         ['dense_3[0][0]']             \n","                                                                                                  \n"," dense_4 (Dense)             (None, 4)                    1028      ['dropout_2[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 314614792 (1.17 GB)\n","Trainable params: 306979528 (1.14 GB)\n","Non-trainable params: 7635264 (29.13 MB)\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/25\n","550/550 [==============================] - 1359s 2s/step - loss: 1.4053 - accuracy: 0.2970 - val_loss: 1.3648 - val_accuracy: 0.3039\n","Epoch 2/25\n","550/550 [==============================] - 177s 322ms/step - loss: 1.3662 - accuracy: 0.3029 - val_loss: 1.3646 - val_accuracy: 0.3039\n","Epoch 3/25\n","119/550 [=====>........................] - ETA: 1:21 - loss: 1.3578 - accuracy: 0.3129"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-96cb81e4353c>\u001b[0m in \u001b[0;36m<cell line: 148>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","# Define dataset folder and classes\n","dataset_folder = '/content/drive/My Drive/masked_directna'\n","classes = sorted(os.listdir(dataset_folder))\n","\n","# Load data\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training',\n","    color_mode='grayscale'\n",")\n","\n","val_generator = datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation',\n","    color_mode='grayscale'\n",")\n","\n","# Define CNN model\n","def create_cnn_model():\n","    model = Sequential([\n","        Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 1)),\n","        MaxPooling2D((2, 2)),\n","        Conv2D(64, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D((2, 2)),\n","        Flatten(),\n","        Dense(64, activation='relu'),\n","        Dense(len(classes), activation='softmax')\n","    ])\n","    return model\n","\n","# Define DenseNet model\n","def create_densenet_model():\n","    base_model = tf.keras.applications.DenseNet121(input_shape=(512, 512, 1),\n","                                                   include_top=False,\n","                                                   weights=None)\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    x = Dense(64, activation='relu')(x)\n","    predictions = Dense(len(classes), activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    return model\n","\n","# Define VGG model\n","def create_vgg_model():\n","    base_model = tf.keras.applications.VGG16(input_shape=(512, 512, 1),\n","                                             include_top=False,\n","                                             weights=None)\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    x = Dense(64, activation='relu')(x)\n","    predictions = Dense(len(classes), activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    return model\n","\n","# Early stopping callback\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n","\n","# Compile and train CNN model\n","cnn_model = create_cnn_model()\n","cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","cnn_model.fit(train_generator,\n","              epochs=20,\n","              validation_data=val_generator,\n","              callbacks=[early_stopping])\n","\n","# Compile and train DenseNet model\n","densenet_model = create_densenet_model()\n","densenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","densenet_model.fit(train_generator,\n","                   epochs=20,\n","                   validation_data=val_generator,\n","                   callbacks=[early_stopping])\n","\n","# Compile and train VGG model\n","vgg_model = create_vgg_model()\n","vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","vgg_model.fit(train_generator,\n","              epochs=20,\n","              validation_data=val_generator,\n","              callbacks=[early_stopping])\n","\n","# Ensemble\n","def ensemble(models, generator):\n","    predictions = np.zeros((generator.samples, len(classes)))\n","    for model in models:\n","        predictions += model.predict(generator)\n","    return np.argmax(predictions, axis=-1)\n","\n","models = [cnn_model, densenet_model, vgg_model]\n","\n","# Performance evaluation\n","def evaluate_ensemble(models, generator):\n","    y_true = generator.classes\n","    y_pred = ensemble(models, generator)\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix(y_true, y_pred))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_true, y_pred, target_names=classes))\n","\n","print(\"Ensemble Model Evaluation:\")\n","evaluate_ensemble(models, val_generator)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"6Tiu3yA_y3MF","executionInfo":{"status":"error","timestamp":1714212350987,"user_tz":-330,"elapsed":101707,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"a7722f08-8aab-40fd-cd0d-dd2cd6305258"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6874 images belonging to 4 classes.\n","Found 1717 images belonging to 4 classes.\n","Epoch 1/20\n","  5/215 [..............................] - ETA: 34:17 - loss: 1.8338 - accuracy: 0.4000"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2f20d855557b>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m cnn_model.fit(train_generator,\n\u001b[0m\u001b[1;32m     79\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Path to your dataset folder\n","dataset_folder = '/content/drive/My Drive/masked_direct'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNidyk3-5AbM","executionInfo":{"status":"ok","timestamp":1714212375461,"user_tz":-330,"elapsed":3202,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"5cabf6ae-b5e3-4f75-9237-5011646ed47b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix\n","from kerastuner.tuners import RandomSearch\n","from kerastuner.engine.hyperparameters import HyperParameters\n","\n","# Define dataset folder and classes\n","dataset_folder = '/content/drive/My Drive/masked_direct'\n","classes = sorted(os.listdir(dataset_folder))\n","\n","# Load data\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training',\n","    color_mode='grayscale'\n",")\n","\n","val_generator = datagen.flow_from_directory(\n","    dataset_folder,\n","    target_size=(512, 512),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='validation',\n","    color_mode='grayscale'\n",")\n","\n","# Define CNN model with hyperparameter tuning\n","def build_cnn_model(hp):\n","    model = Sequential()\n","    model.add(Conv2D(hp.Int('conv1_units', min_value=32, max_value=256, step=32),\n","                     (3, 3),\n","                     activation='relu',\n","                     input_shape=(512, 512, 1)))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(hp.Int('conv2_units', min_value=32, max_value=256, step=32),\n","                     (3, 3),\n","                     activation='relu'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(hp.Int('conv3_units', min_value=32, max_value=256, step=32),\n","                     (3, 3),\n","                     activation='relu'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(hp.Int('dense_units', min_value=32, max_value=256, step=32), activation='relu'))\n","    model.add(Dense(len(classes), activation='softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Define DenseNet model with hyperparameter tuning\n","def build_densenet_model(hp):\n","    base_model = tf.keras.applications.DenseNet121(input_shape=(512, 512, 1),\n","                                                   include_top=False,\n","                                                   weights=None)\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    x = Dense(hp.Int('dense_units', min_value=32, max_value=256, step=32), activation='relu')(x)\n","    predictions = Dense(len(classes), activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Define VGG model with hyperparameter tuning\n","def build_vgg_model(hp):\n","    base_model = tf.keras.applications.VGG16(input_shape=(512, 512, 1),\n","                                             include_top=False,\n","                                             weights=None)\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    x = Dense(hp.Int('dense_units', min_value=32, max_value=256, step=32), activation='relu')(x)\n","    predictions = Dense(len(classes), activation='softmax')(x)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Hyperparameter tuning\n","def hyperparameter_tuning(build_model_func):\n","    tuner = RandomSearch(\n","        build_model_func,\n","        objective='val_accuracy',\n","        max_trials=5,\n","        executions_per_trial=1,\n","        directory='hyperparameter_tuning',\n","        project_name='mask_detection'\n","    )\n","    tuner.search(train_generator, epochs=5, validation_data=val_generator)\n","    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","    return best_hps\n","\n","# Compile and train models\n","def train_model(build_model_func, generator, name):\n","    best_hps = hyperparameter_tuning(build_model_func)\n","    model = build_model_func(best_hps)\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n","    model.fit(generator,\n","              epochs=20,\n","              validation_data=val_generator,\n","              callbacks=[early_stopping])\n","    model.save(f\"{name}_model.h5\")\n","    return model\n","\n","# Train CNN model\n","cnn_model = train_model(build_cnn_model, train_generator, \"cnn\")\n","\n","# Train DenseNet model\n","densenet_model = train_model(build_densenet_model, train_generator, \"densenet\")\n","\n","# Train VGG model\n","vgg_model = train_model(build_vgg_model, train_generator, \"vgg\")\n","\n","# Ensemble\n","def ensemble(models, generator):\n","    predictions = np.zeros((generator.samples, len(classes)))\n","    for model in models:\n","        predictions += model.predict(generator)\n","    return np.argmax(predictions, axis=-1)\n","\n","models = [cnn_model, densenet_model, vgg_model]\n","\n","# Performance evaluation\n","def evaluate_ensemble(models, generator):\n","    y_true = generator.classes\n","    y_pred = ensemble(models, generator)\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix(y_true, y_pred))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_true, y_pred, target_names=classes))\n","\n","print(\"Ensemble Model Evaluation:\")\n","evaluate_ensemble(models, val_generator)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"T6XDztI0FnoH","executionInfo":{"status":"error","timestamp":1714224272838,"user_tz":-330,"elapsed":4488,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"332e8858-4696-4edf-9085-af96a7592648"},"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'kerastuner'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e1865dc25f9d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuners\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!pip install keras-tuner\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imRkiT_hCwEl","executionInfo":{"status":"ok","timestamp":1714213545963,"user_tz":-330,"elapsed":6363,"user":{"displayName":"Adil Ansari","userId":"01083485150708236568"}},"outputId":"464d8336-bc3b-44f6-aa2e-46e6828c641d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras-tuner\n","  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n","\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n","Collecting kt-legacy (from keras-tuner)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n","Installing collected packages: kt-legacy, keras-tuner\n","Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PIkD7DLLFsyU"},"execution_count":null,"outputs":[]}]}